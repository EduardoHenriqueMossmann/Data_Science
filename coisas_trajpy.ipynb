{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eduardo_trajpy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJJugiw7WYIN",
        "outputId": "10baf27f-44a4-477b-c723-d6cb0cf26d31"
      },
      "source": [
        "!pip3 install trajpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trajpy\n",
            "  Downloading trajpy-1.3.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from trajpy) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from trajpy) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from trajpy) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from trajpy) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->trajpy) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->trajpy) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->trajpy) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->trajpy) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.3->trajpy) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->trajpy) (1.0.1)\n",
            "Installing collected packages: trajpy\n",
            "Successfully installed trajpy-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D89JKNLAsmeI"
      },
      "source": [
        "Importando pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2YEgi3Wbnv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import trajpy.trajpy as tj\n",
        "import trajpy.traj_generator as gen\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9wmXq3SpsQH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFiW4xi_spi1"
      },
      "source": [
        "Importando dados trajetória Lennard-Jones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUNYS2YiXDDr"
      },
      "source": [
        "#autocorrelacao = np.loadtxt('vacf2_2.dat')\n",
        "#corr_md_novo = autocorrelacao[:,2] #valor da autocorr.\n",
        "#corr_t_novo = autocorrelacao[:,0] #t da coordenada\n",
        "#msd = np.loadtxt('msd _2.dat')\n",
        "#msd_t = msd[0:170,0]\n",
        "#msd_dx1 = msd[0:170,2]\n",
        "dados = np.loadtxt('snapshot_2.xyz')\n",
        "t_dados = dados[:,0]\n",
        "x1_dados = dados[:,1]\n",
        "x1_dados = x1_dados.reshape(-1,1)\n",
        "t_dados = t_dados.reshape(-1,1)\n",
        "trajetoria = np.concatenate((t_dados,x1_dados),axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3vUnwFYmvoe"
      },
      "source": [
        "x2_dados = dados[:,5]\n",
        "x2_dados = x2_dados.reshape(-1,1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XmWyZt-s8ZI"
      },
      "source": [
        "Função nova para autocorrelação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RwFb8OL6y8C"
      },
      "source": [
        "def autocorrelacao_nova(coor,taus,dt):\n",
        "\n",
        "  media_temporal = np.zeros(len(taus))\n",
        "  velocidade = np.diff(coor, axis=0)/dt\n",
        "  N = len(velocidade)\n",
        "  for tau in taus:\n",
        "    media_temporal[tau] = (np.sum(np.einsum('ij,ij->i',\n",
        "                np.take(a=velocidade,indices=np.arange(0,N-tau)+tau,axis=0),\n",
        "                np.take(a=velocidade,indices=np.arange(0,N-tau),axis=0)))+ \n",
        "                media_temporal[tau-1])*dt / (N-tau)\n",
        "\n",
        "  return media_temporal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-8oSRDzsyr1"
      },
      "source": [
        "Função do Trajpy para autocorrelação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4C3HFElXabz"
      },
      "source": [
        "def autocorrelacao_antiga(coor,tau):\n",
        "    dt = t_dados[1]-t_dados[0]\n",
        "    velocidade = np.diff(coor, axis=0)/dt\n",
        "    time_averaged_corr_velocity = 0.\n",
        "    N = len(velocidade)\n",
        "    correlacao = np.zeros(len(tau))\n",
        "    for value in tau:\n",
        "        for n in range(0, N-value):\n",
        "            time_averaged_corr_velocity += np.dot(velocidade[n+value, :], velocidade[n, :])\n",
        "        time_averaged_corr_velocity = time_averaged_corr_velocity*dt / (N-value)\n",
        "        correlacao[value] = time_averaged_corr_velocity\n",
        "    return correlacao"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_fqfYVZhDz"
      },
      "source": [
        "Plot comparativo da autocorrelação pelo Trajpy, Espresso e função nova "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J54TzKlrZre-"
      },
      "source": [
        "plt.figure(dpi=150)\n",
        "plt.plot(corr_t_novo,corr_md_novo,label='Espresso')\n",
        "plt.plot(np.arange(0,100),autocorrelacao_nova(x1_dados,np.arange(0,100),dt=t_dados[1]-t_dados[0]),label='função nova')\n",
        "plt.xlim(-1,10)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1P-hF_noDt"
      },
      "source": [
        "plt.figure(dpi=150)\n",
        "plt.plot(np.arange(0,20),autocorrelacao_antiga(x1_dados,np.arange(0,20)),label='Função Antiga')\n",
        "plt.plot(np.arange(0,20),autocorrelacao_nova(x1_dados,np.arange(0,20),dt=t_dados[1]-t_dados[0]),label='Função Nova')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbP8RiRbnk7H"
      },
      "source": [
        "Benchmarcks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibyMk5cjXzDq"
      },
      "source": [
        "t = [10,20,40,50,100]\n",
        "run_s_funcao_nova = []\n",
        "run_min_funcao_nova = []\n",
        "for i in t:\n",
        "  import time\n",
        "  inicio = time.time()\n",
        "  correlacao_nova = autocorrelacao_nova(x1_dados,np.arange(0,i),dt=t_dados[1]-t_dados[0])\n",
        "  fim = time.time()\n",
        "  run = fim - inicio\n",
        "  run_s_funcao_nova.append(run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUMhXf48JyrX"
      },
      "source": [
        "run_s_funcao_antiga = []\n",
        "run_min_funcao_antiga = []\n",
        "for i in t:\n",
        "  import time\n",
        "  inicio = time.time()\n",
        "  correlacao_antiga = autocorrelacao_antiga(x1_dados,np.arange(0,i))\n",
        "  fim = time.time()\n",
        "  run = fim - inicio\n",
        "  run_s_funcao_antiga.append(run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdQay0kRaaZq"
      },
      "source": [
        "run_min_funcao_nova = [i/60 for i in run_s_funcao_nova]\n",
        "print('Benchmarks on Google Colab:')\n",
        "for i in range(0,len(t)):\n",
        "  print('Tau =',t[i],':  Função antiga:',run_s_funcao_antiga[i],'segundos;','Função nova:',run_s_funcao_nova[i],'segundos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azKnadpnao3r"
      },
      "source": [
        "t = [10,20,40,50,100]\n",
        "#run_s_funcao_antiga = [44.6,91.1,184.8,231.5,466.4] #valores salvos segundos\n",
        "run_min_funcao_antiga = [i/60 for i in run_s_funcao_antiga]\n",
        "fig = plt.figure(dpi=100)\n",
        "plt.bar(t,run_min_funcao_antiga,width=4.0,label='Função antiga')\n",
        "plt.bar(t,run_min_funcao_nova,width=4.0,label='Função nova')\n",
        "plt.xticks(t)\n",
        "#plt.yticks(run_min)\n",
        "plt.xlabel(r'$\\tau$ Length')\n",
        "plt.ylabel(\"Run Time (min)\")\n",
        "plt.title(\"Run Time x Tau Length for Trajpy Autocorrelation Function in Google Colab\")\n",
        "\n",
        "plt.ylim(0,0.1)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsJ09diGtSTw"
      },
      "source": [
        "Função para gerar arquivo de trajetória pelo traj_generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubEsbiazd8W4"
      },
      "source": [
        "def gen_traj(file_name,length):\n",
        "  # file = file name as string\n",
        "  # length = number of trajectories for each kind\n",
        "  # !!!Cannot change features, must be done by hand!!!\n",
        "  arquivo = open(file_name,'a')\n",
        "  colunas = ['msd_time_average',',','fractal_dimension',',','straightness',',','gaussianity',\n",
        "             ',','efficiency',',','diffusion']\n",
        "  arquivo.writelines(colunas)\n",
        "  arquivo.writelines('\\n')\n",
        "  for i in range(0,length):\n",
        "    tempo,x = gen.normal_diffusion(n_steps=100,n_samples=3,dx=1.0,\n",
        "                                  y0=0.0,D=i+1,dt=0.1)\n",
        "    tempo = tempo.reshape(-1,1)\n",
        "    data = np.concatenate((tempo,x),axis=1)\n",
        "    r = tj.Trajectory()\n",
        "    lista = [str(r.msd_time_averaged(x,1)[0]),',',\n",
        "            str(r.fractal_dimension_(x)[0]),',',\n",
        "            str(r.straightness_(x)),',',\n",
        "            str(r.gaussianity_(x)),',',\n",
        "            str(r.efficiency_(x)),',',\n",
        "            str('normal')]                                                                                       \n",
        "    \n",
        "    arquivo.writelines(lista)\n",
        "    arquivo.writelines('\\n')\n",
        "\n",
        "  for i in range(0,length):\n",
        "    tempo,x = gen.anomalous_diffusion(n_steps=100,n_samples=3,\n",
        "                                      time_step=0.1,alpha=np.random.random())\n",
        "    tempo = tempo.reshape(-1,1)\n",
        "    data = np.concatenate((tempo,x),axis=1)\n",
        "    r = tj.Trajectory()\n",
        "    lista = [str(r.msd_time_averaged(x,1)[0]),',',\n",
        "            str(r.fractal_dimension_(x)[0]),',',\n",
        "            str(r.straightness_(x)),',',\n",
        "            str(r.gaussianity_(x)),',',\n",
        "            str(r.efficiency_(x)),',',\n",
        "            str('anomalous')]  \n",
        "    \n",
        "    arquivo.writelines(lista)\n",
        "    arquivo.writelines('\\n')\n",
        "\n",
        "  for i in range(0,length):\n",
        "    tempo,x = gen.confined_diffusion(radius=i+1,n_steps=100,n_samples=3,\n",
        "                                    dx=1.0,y0=0.0,D=1.0,dt=0.1)\n",
        "    tempo = tempo.reshape(-1,1)\n",
        "    data = np.concatenate((tempo,x),axis=1)\n",
        "    r = tj.Trajectory()\n",
        "    lista = [str(r.msd_time_averaged(x,1)[0]),',',\n",
        "            str(r.fractal_dimension_(x)[0]),',',\n",
        "            str(r.straightness_(x)),',',\n",
        "            str(r.gaussianity_(x)),',',\n",
        "            str(r.efficiency_(x)),',',\n",
        "            str('confined')]\n",
        "    \n",
        "    arquivo.writelines(lista)\n",
        "    arquivo.writelines('\\n')\n",
        "\n",
        "  for i in range(0,length):\n",
        "    tempo,x = gen.superdiffusion(velocity=i+1,n_steps=100,n_samples=3,y0=0.0,dt=0.1)\n",
        "    tempo = tempo.reshape(-1,1)\n",
        "    data = np.concatenate((tempo,x),axis=1)\n",
        "    r = tj.Trajectory()\n",
        "    lista = [str(r.msd_time_averaged(x,1)[0]),',',\n",
        "            str(r.fractal_dimension_(x)[0]),',',\n",
        "            str(r.straightness_(x)),',',\n",
        "            str(r.gaussianity_(x)),',',\n",
        "            str(r.efficiency_(x)),',',\n",
        "            str('superdiffusion')]\n",
        "\n",
        "    arquivo.writelines(lista)\n",
        "    arquivo.writelines('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2EWXSEMtdLw"
      },
      "source": [
        "Chamando a função com argumentos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVq6AsSE4QHh"
      },
      "source": [
        "gen_traj(file_name='trajectories.csv',lenght=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6vNH8pXthx6"
      },
      "source": [
        "Lendo o arquivo de trajetórias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtWLu_uSpAFy"
      },
      "source": [
        "import pandas as pd\n",
        "dados = pd.read_csv('trajectories.csv')\n",
        "dados.columns = ['msd_time_average', 'fractal_dimension', 'straightness', 'gaussianity',\n",
        "       'efficiency', 'diffusion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di_q-iVFtmHt"
      },
      "source": [
        "Plotando gráficos comparativos pelo plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDjbsUVDz6qO"
      },
      "source": [
        "import plotly.express as px\n",
        "df = dados\n",
        "fig = px.scatter_matrix(df,\n",
        "    dimensions=['msd_time_average', 'fractal_dimension', 'straightness', 'gaussianity','efficiency'],\n",
        "    color=dados['diffusion'],width=1000, height=800)\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuuv6LVItrnl"
      },
      "source": [
        "Gerando gráficos comparativos pelo Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB5IjSVOBmf9"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(dados, hue=\"diffusion\",diag_kind='auto')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY5ke-b2tu1h"
      },
      "source": [
        "Importando Decision Tree Classifier (validação cruzada,fit e matriz de confusão)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBhVNyL5R4p9"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bicVjLx9WmwM",
        "outputId": "9863f17c-7eab-4d34-c00a-56ca957b9261"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score #importa o cálculo da acurácia do modelo\n",
        "from  sklearn.model_selection import StratifiedKFold #importa o método de subdivisão  \n",
        "y = dados['diffusion']\n",
        "x = dados.drop('diffusion',axis=1)\n",
        "skfold = StratifiedKFold(n_splits=5) #separamos em 5 subdivisões\n",
        "\n",
        "#criando o modelo\n",
        "modelo = DecisionTreeClassifier()\n",
        "resultado = cross_val_score(modelo,x,y,cv=skfold)\n",
        "print(resultado.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ZwQupfXgzw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "xtreino,xteste,ytreino,yteste = train_test_split(x,y,test_size=0.7)\n",
        "modelo.fit(xtreino,ytreino)\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.set_ylabel('True Label', fontsize=15)\n",
        "ax.set_xlabel('Predicted Label', fontsize=15)\n",
        "ax.tick_params(axis='y',labelsize=15) \n",
        "ax.tick_params(axis='x',labelsize=15)\n",
        "ax.set_title('Classification Confusion Matrix',fontdict={'fontsize': 20})\n",
        "plot_confusion_matrix(modelo, xteste, yteste,cmap='Blues',ax=ax,xticks_rotation='50') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUiX9NC1YWvS"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "y_keras = dados['diffusion']\n",
        "y_keras.replace('normal',0,inplace=True)\n",
        "y_keras.replace('anomalous',1,inplace=True)\n",
        "y_keras.replace('confined',2,inplace=True)\n",
        "y_keras.replace('superdiffusion',3,inplace=True)\n",
        "x_keras = dados.drop('diffusion',axis=1)\n",
        "y_convertido = np_utils.to_categorical(y_keras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYbGl8FIt-dh"
      },
      "source": [
        "Importando pacotes Keras para fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT7qdNiOhG-N"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtreino_keras,xteste_keras,ytreino_keras,yteste_keras = train_test_split(x_keras,y_convertido,test_size=0.7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmvq4RVGiNeE",
        "outputId": "e62e66c6-e99d-4105-8ddd-5c41cff82b8f"
      },
      "source": [
        "from keras.models import Sequential #modelo par criar uma rede neural sequencial, onde cada camada se conceta com a\n",
        "#próxima\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD #importa o método de otimização do Gradiente Descendente Estocástico\n",
        "modelo_keras = Sequential()\n",
        "modelo_keras.add(Dense(10,input_dim=5,kernel_initializer='normal',activation='sigmoid'))\n",
        "modelo_keras.add(Dense(4,kernel_initializer='normal',activation='softmax'))\n",
        "otimizador = keras.optimizers.SGD()\n",
        "modelo_keras.compile(loss='categorical_crossentropy',optimizer=otimizador,metrics=['acc'])\n",
        "modelo_keras.fit(xtreino_keras,ytreino_keras,epochs=1000,batch_size=30,validation_data=(xteste_keras,yteste_keras),verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75c96e4610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVhLdHjIrWPr"
      },
      "source": [
        "y_pred = modelo_keras.predict_classes(xteste_keras,batch_size=32,verbose=0)\n",
        "classes = np.zeros(4) \n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i] == 0:\n",
        "    classes[0] += 1\n",
        "  elif y_pred[i] == 1:\n",
        "    classes[1] += 1\n",
        "  elif y_pred[i] == 2:\n",
        "    classes[2] += 1\n",
        "  else:\n",
        "    classes[3] +=1\n",
        "print(classes)\n",
        "print(sum(classes))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt17fmWB2cBE"
      },
      "source": [
        "Plotly 3D Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4wnXKTfpGIy"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(0.0, 3.0, 50)\n",
        "y = np.linspace(0.0, 3.0, 50)\n",
        "xGrid, yGrid = np.meshgrid(y, x)\n",
        "\n",
        "def teste(xGrid,yGrid,n): #INTERACTIVE GRAPH\n",
        "    z = 0.0\n",
        "    for i in range(1,n,2):\n",
        "        z = z + np.sin(i*yGrid)/(i*np.e**(i*xGrid))\n",
        "        #print(np.sin(i*yGrid))\n",
        "    return z\n",
        "Z = teste(xGrid,yGrid,2)\n",
        "\n",
        "fig = fig = go.Figure(data=[go.Surface(z=Z, x=xGrid, y=yGrid)])\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTAYiDsW2l4o"
      },
      "source": [
        "Regular 3D Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiui8M9ub33P"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = np.linspace(-1.0,1.0,20)\n",
        "y = np.linspace(0.0,1.0,20)\n",
        "X,Y = np.meshgrid(x,y)\n",
        "def funcao(x,y):    #REGULAR 3D GRAPH\n",
        "    for i in range(1,20,2):\n",
        "        return 4/i*(np.cosh(i*np.pi*x))/(np.cosh(i*np.pi))*np.sin(i*np.pi*y)\n",
        "Z = funcao(X,Y)\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot_surface(X,Y,Z,cmap='magma')\n",
        "ax.set_xlabel('s/R')\n",
        "ax.set_ylabel('phi')\n",
        "ax.set_zlabel('V/V0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8ncu_x82uhL"
      },
      "source": [
        "Gráfico autocorrelação com ZOOM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVKP8V-lcCyi"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes,mark_inset\n",
        "if __name__=='__main__':\n",
        "    fig = plt.figure(dpi=150)\n",
        "    ax = plt.subplot(111) #whole path\n",
        "    plt.title('Velocity Autocorrelation Function')\n",
        "    plt.ylabel(r'$C(\\tau)$')\n",
        "    plt.xlabel(r'$\\tau$')\n",
        "    plt.plot(correlacao[:,0],correlacao[:,1],label='ESPResSo')\n",
        "    plt.plot(np.arange(0,100),autocorrelacao_nova(x1_dados,np.arange(0,100),dt=t_dados[1]-t_dados[0])\n",
        "         ,label='TrajPy')\n",
        "    ax.set_xlim(-1,100) #altera limites do eixo x do gráfico principal\n",
        "    ax.set_ylim(-1,6) #altera limites do eixo y do gráfico principal\n",
        "    #ax.grid()\n",
        "    ax.legend() #legendas do gráfico principal\n",
        "\n",
        "    axins = zoomed_inset_axes(ax,3,loc='center') #número altera o tamanho do zoom e loc altera a localização\n",
        "    #da janela de zoom\n",
        "    axins.plot(correlacao[:,0],correlacao[:,1])\n",
        "    axins.plot(np.arange(0,100),autocorrelacao_nova(x1_dados,np.arange(0,100),dt=t_dados[1]-t_dados[0]))\n",
        "\n",
        "    x1,x2,y1,y2 = 37,59, -0.5,0.5 #altera os limites para a região que daremos zoom\n",
        "    axins.set_xlim(x1,x2)\n",
        "    axins.set_ylim(y1,y2)\n",
        "    #axins.grid()\n",
        "\n",
        "    #mark_inset(ax,axins,loc1=3,loc2=4) #altera de quais vértices saem as linhas diagonais do zoom\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VynmFlSc270D"
      },
      "source": [
        "Fast Fourier Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp6TzKIpHkRn"
      },
      "source": [
        "def fftPlot(sig, dt=None, plot=True):\n",
        "    # Here it's assumes analytic signal (real signal...) - so only half of the axis is required\n",
        "\n",
        "    if dt is None:\n",
        "        dt = 1\n",
        "        t = np.arange(0, sig.shape[-1])\n",
        "        xLabel = 'samples'\n",
        "    else:\n",
        "        t = np.arange(0, sig.shape[-1]) * dt\n",
        "        xLabel = 'freq [Hz]'\n",
        "\n",
        "    if sig.shape[0] % 2 != 0:\n",
        "        warnings.warn(\"signal preferred to be even in size, autoFixing it...\")\n",
        "        t = t[0:-1]\n",
        "        sig = sig[0:-1]\n",
        "\n",
        "    sigFFT = np.fft.fft(sig) / t.shape[0]  # Divided by size t for coherent magnitude\n",
        "\n",
        "    freq = np.fft.fftfreq(t.shape[0], d=dt)\n",
        "\n",
        "    # Plot analytic signal - right half of frequence axis needed only...\n",
        "    firstNegInd = np.argmax(freq < 0)\n",
        "    freqAxisPos = freq[0:firstNegInd]\n",
        "    sigFFTPos = 2 * sigFFT[0:firstNegInd]  # *2 because of magnitude of analytic signal\n",
        "    \n",
        "    for i in range(len(np.abs(sigFFTPos))):\n",
        "      if (np.round(np.abs(sigFFTPos),1))[i] > 0:\n",
        "        max_index = i\n",
        "\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(dpi=150)\n",
        "        plt.title('Analytic FFT plot')\n",
        "        plt.subplot(211)\n",
        "        plt.xlabel('Time [unit]')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.plot(t,sig)\n",
        "        #plt.ylim(min(sinal)-10,max(sinal)+10)\n",
        "\n",
        "        plt.subplot(212)\n",
        "        plt.xlabel(xLabel)\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.xlim(0,freqAxisPos[max_index]+10)\n",
        "        plt.plot(freqAxisPos, np.abs(sigFFTPos))\n",
        "        plt.grid()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    #return sigFFTPos, freqAxisPos"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNiPyjGoHvc-"
      },
      "source": [
        "dt = 1/1000\n",
        "time = np.arange(0,10,dt)\n",
        "sinal =  5.3*np.sin(2*np.pi*83.3*time) + 9.9*np.sin(2*np.pi*27.1*time) + 1.1*np.sin(2*np.pi*33.3*time) + 3.7*np.sin(2*np.pi*21.9*time)\n",
        "\n",
        "fftPlot(sig=sinal,dt=dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWUtA_W3EKj"
      },
      "source": [
        "Novas features para velocidade:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsEMtKURgOBG"
      },
      "source": [
        "def velocity_(position,t):\n",
        "        \"\"\"\n",
        "            computes the velocity associated with the trajectory stored in (self._r, self._t)\n",
        "        \"\"\"\n",
        "        \n",
        "        velocity = np.diff(position, axis=0)/(t[1]-t[0])\n",
        "\n",
        "        return velocity"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjDCkBQ13Dkm"
      },
      "source": [
        "def velocity_description_(velocity): #descrição completa em uma função?\n",
        "    \"\"\"\n",
        "        computes the skewness (lack of simmetry) of a frequency distribuition.Positive result implies \n",
        "        distribuition's tail to the right, negative implies tail to the left and zero implies simmetric\n",
        "        distribuition\n",
        "        \n",
        "        .. math::\n",
        "                g_1 = \\\\frac{m_3}{m_2^{\\\\frac{3}{2}}}\n",
        "        \n",
        "        :param data: data to be analyzed\n",
        "        :return skewness: skewness\n",
        "    \"\"\"\n",
        "    \n",
        "    mean = np.mean(velocity,axis=0) #média das velocidades\n",
        "    median = np.median(velocity,axis=0) #mediana das velocidades\n",
        "    standard_deviation = np.std(velocity,axis=0) #desvio padrão das velocidades\n",
        "    variance = np.var(velocity,axis=0) #variância das velocidades\n",
        "    #range = max(v1)-min(v1),max(v2)-min(v2),...??????? \n",
        "    ############ SKEWNESS ####################################\n",
        "    m3 = np.zeros(velocity.shape[1])\n",
        "    m2 = np.zeros(velocity.shape[1])\n",
        "    skewness = np.zeros(velocity.shape[1])\n",
        "    for i in range(velocity.shape[1]):\n",
        "      for l in range(len(velocity)):\n",
        "        m3[i] += (velocity[l,i] - mean[i])**3\n",
        "        m2[i] += (velocity[l,i] - mean[i])**2\n",
        "    m2 = m2/len(velocity)\n",
        "    m3 = m3/len(velocity)\n",
        "    skewness = m3/(m2**1.5)\n",
        "    ########### KURTOSIS ####################################\n",
        "    kurtosis = np.zeros(velocity.shape[1])\n",
        "    m4 = np.zeros(velocity.shape[1])\n",
        "    for i in range(velocity.shape[1]):\n",
        "        for l in range(len(velocity)):\n",
        "           m4[i] += (velocity[l,i] - mean[i])**4\n",
        "    m4 = m4/len(velocity)\n",
        "    kurtosis = m4/(standard_deviation**4) + (-3)\n",
        "    ######## MODE ##########################################\n",
        "    # ??????????????????????????????????????????????\n",
        "    return mean, median, standard_deviation,variance,skewness,kurtosis"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUfgqEJvlWr9"
      },
      "source": [
        "posicao = np.concatenate((x1_dados,x2_dados),axis=1)\n",
        "velocidade = velocity_(posicao,t_dados)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKDxyIVC1ri8"
      },
      "source": [
        "descricao = velocity_description_(velocidade)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l312xwwp9nLF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}